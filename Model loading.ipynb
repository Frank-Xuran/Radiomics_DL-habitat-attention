{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306c89e4",
   "metadata": {},
   "source": [
    "# Model building and loading trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd89ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "try:\n",
    "    in_channels = args.__getattribute__('in_channels')\n",
    "except:\n",
    "    in_channels = 1\n",
    "    import math\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from collections import OrderedDict\n",
    "\n",
    "\n",
    "    class _DenseLayer(nn.Sequential):\n",
    "\n",
    "        def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "            super().__init__()\n",
    "            self.add_module('norm1', nn.BatchNorm3d(num_input_features))\n",
    "            self.add_module('relu1', nn.ReLU(inplace=True))\n",
    "            self.add_module(\n",
    "                'conv1',\n",
    "                nn.Conv3d(num_input_features,\n",
    "                          bn_size * growth_rate,\n",
    "                          kernel_size=3,\n",
    "                          stride=1,\n",
    "                          padding=1,\n",
    "                          bias=False))\n",
    "            self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate))\n",
    "            self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "            self.add_module(\n",
    "                'conv2',\n",
    "                nn.Conv3d(bn_size * growth_rate,\n",
    "                          growth_rate,\n",
    "                          kernel_size=3,\n",
    "                          stride=1,\n",
    "                          padding=1,\n",
    "                          bias=False))\n",
    "            self.drop_rate = drop_rate\n",
    "\n",
    "        def forward(self, x):\n",
    "            new_features = super().forward(x)\n",
    "            if self.drop_rate > 0:\n",
    "                new_features = F.dropout(new_features,\n",
    "                                         p=self.drop_rate,\n",
    "                                         training=self.training)\n",
    "            return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "    class _DenseBlock(nn.Sequential):\n",
    "\n",
    "        def __init__(self, num_layers, num_input_features, bn_size, growth_rate,\n",
    "                     drop_rate):\n",
    "            super().__init__()\n",
    "            for i in range(num_layers):\n",
    "                layer = _DenseLayer(num_input_features + i * growth_rate,\n",
    "                                    growth_rate, bn_size, drop_rate)\n",
    "                self.add_module('denselayer{}'.format(i + 1), layer)\n",
    "\n",
    "\n",
    "    class _Transition(nn.Sequential):\n",
    "\n",
    "        def __init__(self, num_input_features, num_output_features):\n",
    "            super().__init__()\n",
    "            self.add_module('norm', nn.BatchNorm3d(num_input_features))\n",
    "            self.add_module('relu', nn.ReLU(inplace=True))\n",
    "            self.add_module(\n",
    "                'conv',\n",
    "                nn.Conv3d(num_input_features,\n",
    "                          num_output_features,\n",
    "                          kernel_size=1,\n",
    "                          stride=1,\n",
    "                          bias=False))\n",
    "            self.add_module('pool', nn.MaxPool3d(kernel_size=1, stride=2))\n",
    "\n",
    "\n",
    "    class DenseNet(nn.Module):\n",
    "        \"\"\"\n",
    "        Densenet-BC model class\n",
    "\n",
    "        Args:\n",
    "            growth_rate (int) - how many filters to add each layer (k in paper)\n",
    "            block_config (list of 4 ints) - how many layers in each pooling block\n",
    "            num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "            bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "              (i.e. bn_size * k features in the bottleneck layer)\n",
    "            drop_rate (float) - dropout rate after each dense layer\n",
    "            num_classes (int) - number of classification classes\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self,\n",
    "                     in_channels=1,\n",
    "                     conv1_t_size=5,\n",
    "                     conv1_t_stride=2,\n",
    "                     no_max_pool=False,\n",
    "                     growth_rate=32,\n",
    "                     block_config=(6, 12, 24, 16),\n",
    "                     num_init_features=64,\n",
    "                     bn_size=4,\n",
    "                     drop_rate=0,\n",
    "                     num_classes=2,\n",
    "                     **kwargs):\n",
    "\n",
    "            super().__init__()\n",
    "\n",
    "            # First convolution\n",
    "            self.features = [('conv1',\n",
    "                              nn.Conv3d(in_channels,\n",
    "                                        num_init_features,\n",
    "                                        kernel_size=(conv1_t_size, 5, 5),\n",
    "                                        stride=(conv1_t_stride, 2, 2),\n",
    "                                        padding=(1, 1, 1),\n",
    "                                        bias=False)),\n",
    "                             ('norm1', nn.BatchNorm3d(num_init_features)),\n",
    "                             ('relu1', nn.ReLU(inplace=True))]\n",
    "            if not no_max_pool:\n",
    "                self.features.append(\n",
    "                    ('pool1', nn.AvgPool3d(kernel_size=3, stride=2, padding=1)))\n",
    "\n",
    "            self.features = nn.Sequential(OrderedDict(self.features))\n",
    "            self.attention_module = AttentionModule(num_init_features)\n",
    "\n",
    "            num_features = num_init_features\n",
    "            self.blocks_and_transitions = nn.ModuleList()\n",
    "\n",
    "            for i, num_layers in enumerate(block_config):\n",
    "                # Each denseblock\n",
    "                block = _DenseBlock(num_layers=num_layers,\n",
    "                                    num_input_features=num_features,\n",
    "                                    bn_size=bn_size,\n",
    "                                    growth_rate=growth_rate,\n",
    "                                    drop_rate=drop_rate)\n",
    "                self.blocks_and_transitions.append(block)\n",
    "                num_features += num_layers * growth_rate\n",
    "\n",
    "                # Each transition\n",
    "                if i != len(block_config) - 1:  # 不在最后一个DenseBlock后添加Transition\n",
    "                    trans = _Transition(num_input_features=num_features,\n",
    "                                        num_output_features=num_features // 2)\n",
    "                    self.blocks_and_transitions.append(trans)\n",
    "                    num_features //= 2\n",
    "\n",
    "            # Final batch norm\n",
    "            self.final_norm = nn.BatchNorm3d(num_features)\n",
    "\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv3d):\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                elif isinstance(m, nn.BatchNorm3d) or isinstance(m, nn.BatchNorm2d):\n",
    "                    m.weight.data.fill_(1)\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "            # Linear layer\n",
    "            self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv3d):\n",
    "                    nn.init.kaiming_normal_(m.weight,\n",
    "                                            mode='fan_out',\n",
    "                                            nonlinearity='relu')\n",
    "                elif isinstance(m, nn.BatchNorm3d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        def forward(self, x, mask):\n",
    "            x = self.features(x)\n",
    "            x = self.attention_module(x, mask)\n",
    "            for i, block in enumerate(self.blocks_and_transitions):\n",
    "                x = block(x)\n",
    "            x = self.final_norm(x)\n",
    "            x = F.relu(x, inplace=True)\n",
    "            x = F.adaptive_avg_pool3d(x, output_size=(1, 1, 1)).view(x.size(0), -1)\n",
    "            # Apply classifier\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "    def generate_model(model_depth, custom_block_config=None, **kwargs):\n",
    "        assert model_depth in [121, 169, 201, 264, 'my']\n",
    "\n",
    "        # Traditional DenseNet or custom architecture\n",
    "        if custom_block_config is None:\n",
    "            if model_depth == 121:\n",
    "                block_config = (6, 12, 24, 16)\n",
    "            elif model_depth == 169:\n",
    "                block_config = (6, 12, 32, 32)\n",
    "            elif model_depth == 201:\n",
    "                block_config = (6, 12, 48, 32)\n",
    "            elif model_depth == 264:\n",
    "                block_config = (6, 12, 64, 48)\n",
    "        else:\n",
    "            block_config = custom_block_config\n",
    "\n",
    "        model = DenseNet(num_init_features=64,\n",
    "                         growth_rate=32,\n",
    "                         block_config=block_config,\n",
    "                         **kwargs)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def DenseNet121(**kwargs):\n",
    "        return generate_model(121, **kwargs)\n",
    "\n",
    "\n",
    "    def DenseNet169(**kwargs):\n",
    "        return generate_model(169, **kwargs)\n",
    "\n",
    "\n",
    "    def DenseNet201(**kwargs):\n",
    "        return generate_model(201, **kwargs)\n",
    "\n",
    "\n",
    "    def DenseNet264(**kwargs):\n",
    "        return generate_model(264, **kwargs)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, num_input_features):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.attention_coefficient = nn.Parameter(torch.ones([1], dtype=torch.float32))\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
    "        self.norm1 = nn.BatchNorm3d(64)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.AvgPool3d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, feature_map, mask):\n",
    "  \n",
    "        mask = torch.where(mask > 0, torch.tensor(1.0, device=mask.device), torch.tensor(0.0, device=mask.device))\n",
    "\n",
    "        mask_processed = self.conv1(mask)\n",
    "        mask_processed = self.norm1(mask_processed)\n",
    "        mask_processed = self.ReLU(mask_processed)\n",
    "        mask_processed = self.pool1(mask_processed)\n",
    "        mask_processed = torch.where(mask_processed > 0, torch.tensor(1.0, device=mask_processed.device),\n",
    "                                     torch.tensor(0.0, device=mask_processed.device))\n",
    "        # Softplus activation weights\n",
    "        positive_attention_coefficient = self.softplus(self.attention_coefficient)+1\n",
    "        #habitat attention feature map\n",
    "        return feature_map *  positive_attention_coefficient * mask_processed\n",
    "custom_model = generate_model(\"my\", custom_block_config=(2,4,4,2),drop_rate=0.2)\n",
    "\n",
    "\n",
    "\n",
    "model=custom_model.to(device)  \n",
    "# Kaiming/He initialization\n",
    "import torch.nn as nn\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# apply initialization\n",
    "model.apply(init_weights)\n",
    "#Loading trained weights \n",
    "model.load_state_dict(torch.load('C:/Users/XuRan/Desktop/mode_spilt_benchMark-final/Trained model.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f58db",
   "metadata": {},
   "source": [
    "# Print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9f7c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv1): Conv3d(1, 64, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pool1): AvgPool3d(kernel_size=3, stride=2, padding=1)\n",
       "  )\n",
       "  (attention_module): AttentionModule(\n",
       "    (softplus): Softplus(beta=1, threshold=20)\n",
       "    (conv1): Conv3d(1, 64, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU): ReLU(inplace=True)\n",
       "    (pool1): AvgPool3d(kernel_size=3, stride=2, padding=1)\n",
       "  )\n",
       "  (blocks_and_transitions): ModuleList(\n",
       "    (0): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): _Transition(\n",
       "      (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (pool): MaxPool3d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(160, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): _Transition(\n",
       "      (norm): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (pool): MaxPool3d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(160, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(192, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): _Transition(\n",
       "      (norm): BatchNorm3d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv3d(224, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (pool): MaxPool3d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (6): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(112, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv3d(144, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): BatchNorm3d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Linear(in_features=176, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43020ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
